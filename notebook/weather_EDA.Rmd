---
title: "weather data EDA"
author: "Junxiong Liu"
date: '`r format(Sys.time(), "%B %d, %Y")`'
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse=TRUE, prompt=TRUE, eval=TRUE, message=F, include=T,comment=NULL,fig.width = 5, warnings = FALSE, fig.height = 3,tidy.opts=list(width.cutoff=50),tidy=TRUE)
```

```{r packageCheck, include=FALSE}
mypacks <- c("ggplot2","stringr","dplyr","knitr","formattable","boot","readr","lubridate")  # what packages are needed?
packs <- installed.packages()   # find installed package list
install.me <- mypacks[!(mypacks %in% packs[,"Package"])]  #what needs to be installed?
if (length(install.me) >= 1) install.packages(install.me, repos = "http://cran.us.r-project.org")   # install (if needed)
lapply(mypacks, library, character.only=TRUE)  # load all packages
```

# Read Data
```{r}
weather <- read_csv("../../data/weather.csv")
train <- read_csv("../../data/train.csv")
metadata <- read_csv("../../data/metadata.csv")
submission_frequency <- read_csv("../../data/submission_frequency.csv")
holidays <- read_csv("../../data/holidays.csv")
test <- read_csv("../../data/submission_format.csv")
```

# EDA
```{r}
# columns names
names(weather)

# quick summary of columns
summary(weather)

# quick check about time
site_1_train <- train %>% filter(SiteId == 1)
site_1_weather <- weather %>% filter(SiteId == 1)

# quality check
temp0_train <- train %>%
  group_by(SiteId) %>%
  summarise(n=n()) # 267 sites existed in the train

temp0_test <- test %>%
  group_by(SiteId) %>%
  summarise(n=n()) # same as temp0_train

# train and test consistent
anti_join(temp0_train %>% select(SiteId),temp0_test %>% select(SiteId))

temp0_weather <- weather %>%
  group_by(SiteId) %>%
  summarise(n=n()) # 247 sites  have weather info.

# 52 sites do not have weather info!!!
nrow(anti_join(temp0_train %>% select(SiteId),temp0_weather %>% select(SiteId)))
```

# idea: 
- "cut" the range of data for weather data to reduce size
- join by site id
- calculate the difference between timestampe in weather and timestamp in train; set a threshold (i.e. < 15min) for weather to use 

# try to reduce the amount of data
```{r}
# for weather, create two columns: train start and train end
temp <- train %>% 
  group_by(SiteId) %>%
  mutate(min_time_train = min(Timestamp),max_time_train = max(Timestamp)) %>%
  ungroup() %>% select(SiteId,min_time_train,max_time_train) %>%
  distinct(SiteId,min_time_train,max_time_train)

# same for test
temp2 <- test %>% 
  group_by(SiteId) %>%
  mutate(min_time_test = min(Timestamp),max_time_test = max(Timestamp)) %>%
  ungroup() %>% select(SiteId,min_time_test,max_time_test) %>%
  distinct(SiteId,min_time_test,max_time_test)

weather_new <- left_join(weather,temp,by="SiteId")
weather_new <- left_join(weather_new,temp2,by="SiteId")


# set a threshold to cut weather data
low_cut <- 2 # cut to the point 2 years before

# first_1000 <- weather_new %>% slice(1:1000)

weather_new_filtered <- weather_new %>%
  mutate(max_time = as_datetime(ifelse(max_time_train > max_time_test,max_time_train,max_time_test)),
         min_time = as_datetime(ifelse(min_time_train < min_time_test,min_time_train,min_time_test))) %>%
  mutate(smaller_than_max = ifelse(Timestamp < max_time,1,0),
         bigger_than_min = ifelse(Timestamp > min_time - years(low_cut),1,0))

# check NA's there
weather_new_filtered_NA <- weather_new_filtered %>%
  filter(is.na(smaller_than_max)) 
# i.e. siteId 4 is in weather not in train/test, but have weather data

# get rid of NA's and not meeting threshold in weather_new_filtered
weather_new_filtered_2 <- weather_new_filtered %>%
  filter(!is.na(smaller_than_max)) %>%
  filter(smaller_than_max == 1,bigger_than_min==1)

summary(weather_new_filtered_2)
```

# for each site and each timestamp only use the one with closest distance 
# if same distance and same timestamp for the site, use average temperature
```{r}
weather_new_filtered_3 <- weather_new_filtered_2 %>%
  group_by(SiteId,Timestamp) %>% 
  filter(Distance == min(Distance)) %>%
  ungroup() %>%
  group_by(SiteId,Timestamp,Distance) %>%
  summarise(Weather=mean(Temperature))
  
nrow(weather_new_filtered_3)/nrow(weather_new) # 42% of weather data remaining
```

# output
```{r}
write_csv(weather_new_filtered_3,"weather_cleaned.csv")
```



# archived code
```{r}
# change date format to lubridate
weather_new2 <- weather_new %>%
  slice(400000:401000) %>%
  mutate(Timestamp = ymd_hms(Timestamp),
         min_time_train = ymd_hms(min_time_train),
         max_time_train = ymd_hms(max_time_train),
         min_time_test = ymd_hms(min_time_test),
         max_time_test = ymd_hms(max_time_test))
```

